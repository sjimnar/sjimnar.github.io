{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the AWS Security Blog!","text":"<p>You've come to the right place if you're looking to enhance your Amazon cloud security. This blog is dedicated to sharing analysis, insights, and countermeasures related to various security techniques and attack patterns within the Amazon Web Services (AWS) ecosystem. Here you will find articles aimed at disseminating knowledge and providing practical mitigation strategies to strengthen your cloud security posture.</p>"},{"location":"about/","title":"About Me","text":"<p>Hello! I'm Sergio Jimenez, and this is my blog dedicated to AWS security.</p> <p>I am passionate about cloud security, particularly in the Amazon Web Services (AWS) ecosystem. My goal with this blog is to share insights, analysis, and countermeasures related to various security techniques and attack patterns in AWS.</p> <p>I often draw inspiration from resources like Stratus Red Team to explore and explain complex security scenarios, helping to disseminate knowledge and provide practical mitigation strategies.</p> <p>Feel free to connect with me on LinkedIn or join our Discord community to discuss AWS security topics.</p>"},{"location":"blog/","title":"Blog","text":""},{"location":"blog/2025/06/25/iam-access-analyzer---a-cloud-guardian-for-your-s3-buckets/","title":"IAM Access Analyzer - A Cloud Guardian for Your S3 Buckets","text":"<p>In the vast and ever-expanding AWS ecosystem, permission management is crucial. A simple misconfiguration in an S3 bucket policy can expose sensitive data, opening a backdoor for attackers. This is where IAM Access Analyzer steps in, acting as an unyielding sentinel to protect your resources by detecting unwanted external access.</p>","tags":["aws","security","iam"]},{"location":"blog/2025/06/25/iam-access-analyzer---a-cloud-guardian-for-your-s3-buckets/#why-iam-access-analyzer-is-crucial-for-s3","title":"Why IAM Access Analyzer is Crucial for S3","text":"<p>Imagine you've set up an S3 bucket to store critical information. Unbeknownst to you, a poorly configured policy could grant access to an external AWS account or, worse yet, make the bucket publicly accessible. While GuardDuty excels at detecting attack patterns and anomalous activities, and CloudTrail logs all actions, IAM Access Analyzer specializes in the proactive detection of risky policy configurations.</p> <p>For instance, GuardDuty might not alert you about a policy granting access to a specific AWS account (as it's not \"anonymous\" or \"public\" access in the strict sense that GuardDuty looks for with certain detections). However, Access Analyzer will. Its primary goal is to identify resources accessible from outside your \"zone of trust,\" which includes AWS accounts external to your organization.</p>","tags":["aws","security","iam"]},{"location":"blog/2025/06/25/iam-access-analyzer---a-cloud-guardian-for-your-s3-buckets/#how-external-access-detection-works","title":"How External Access Detection Works","text":"<p>IAM Access Analyzer uses logical reasoning to analyze the policies of your resources, including S3 buckets. When you enable it in a region, you define your account or organization as your \"zone of trust.\" It then evaluates all resource policies, searching for any statement that grants permissions to entities outside that zone of trust.</p> <p>When IAM Access Analyzer detects a policy that allows an external entity to perform actions on your S3 buckets, it generates a finding. These findings alert you to potential access and provide details like:</p> <ul> <li>Finding type: For example, public access or cross-account access.</li> <li>Affected resource: The S3 bucket's ARN.</li> <li>Allowed action: The S3 operations the external entity can perform (e.g., <code>s3:GetObject</code>, <code>s3:ListBucket</code>).</li> <li>External principal: The identity (an AWS account, an IAM user, a role, etc.) that has access.</li> </ul> <p>This is incredibly valuable because it lets you identify and remediate security configurations before they can be exploited.</p>","tags":["aws","security","iam"]},{"location":"blog/2025/06/25/iam-access-analyzer---a-cloud-guardian-for-your-s3-buckets/#example-scenario-the-backdoor-policy","title":"Example Scenario: The Backdoor Policy","text":"<p>Consider the following example of an S3 bucket policy that could be used as a \"backdoor\" to exfiltrate data:</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"AWS\": \"arn:aws:iam::193672423079:root\"\n            },\n            \"Action\": [\n                \"s3:GetObject\",\n                \"s3:GetBucketLocation\",\n                \"s3:ListBucket\"\n            ],\n            \"Resource\": [\n                \"arn:aws:s3:::my-secret-bucket/*\",\n                \"arn:aws:s3:::my-secret-bucket\"\n            ]\n        }\n    ]\n}\n</code></pre> <p>This policy allows the root AWS account with ID 193672423079 to access <code>my-secret-bucket</code>. If this account isn't part of your organization, IAM Access Analyzer will generate a finding, as it will detect this cross-account access as a potential vulnerability. It will notify you that your bucket has a policy allowing an external entity to access its content, enabling you to take immediate action.</p>","tags":["aws","security","iam"]},{"location":"blog/2025/06/25/iam-access-analyzer---a-cloud-guardian-for-your-s3-buckets/#how-to-enable-and-use-iam-access-analyzer","title":"How to Enable and Use IAM Access Analyzer","text":"<ul> <li>Enablement: Go to the AWS IAM console, navigate to Access Analyzer, and enable it for the region where your S3 buckets are located. You can choose to analyze your current account or your entire AWS organization.</li> <li>Finding Review: Once enabled, Access Analyzer will begin scanning your resources. Findings will appear in the Access Analyzer dashboard. Review them regularly.</li> <li>Action: For each finding, determine if the access is intended and secure. If not, modify the bucket policy to revoke the unwanted access. IAM Access Analyzer even helps you generate a secure policy to fix the issue.</li> </ul>","tags":["aws","security","iam"]},{"location":"blog/2025/06/25/defending-s3---anatomy-and-countermeasures-for-encryption-and-deletion-attacks-codefinger-ransomware/","title":"Defending S3: Anatomy and Countermeasures for Encryption and Deletion Attacks (Codefinger ransomware)","text":"<p>Lately, we're seeing an attack pattern against Amazon S3 that is brutally simple and effective. Attackers don't need a zero-day exploit in AWS. They just need one thing: a set of compromised AWS credentials. With that, they can either delete or hijack all your data.</p> <p>In this post, we're going to break down the anatomy of two specific tactics gaining popularity and, more importantly, walk through the defense playbook to make sure it doesn't happen to you. Because under the shared responsibility model, whether your data in S3 is still there tomorrow depends on the defenses you implement today.</p>","tags":["aws","security","ransomware"]},{"location":"blog/2025/06/25/defending-s3---anatomy-and-countermeasures-for-encryption-and-deletion-attacks-codefinger-ransomware/#the-anatomy-of-the-attacks","title":"The Anatomy of the Attacks","text":"<p>Both attacks start the same way: the attacker gets their hands on valid credentials with permissions over your buckets. From there, the path forks.</p>","tags":["aws","security","ransomware"]},{"location":"blog/2025/06/25/defending-s3---anatomy-and-countermeasures-for-encryption-and-deletion-attacks-codefinger-ransomware/#tactic-1-ransomware-via-batch-deletion","title":"Tactic 1: Ransomware via Batch Deletion","text":"<p>This is a scorched-earth attack. The goal is simple: wipe everything and leave a ransom note. It's fast and destructive.</p> <ol> <li>Inventory: First, the attacker needs to know what to delete. They make a <code>ListObjectVersions</code> API call to get a complete list of every object and every version within the target bucket.</li> <li>Annihilation: With the list in hand, they use the <code>DeleteObjects</code> API. This operation is terrifyingly efficient for malicious purposes, as it can delete up to 1,000 objects (and their versions) in a single request. A simple loop in a script can empty a bucket with millions of objects in a very short time.</li> <li>The Note: Once the bucket is empty, the attacker uploads a file, typically named <code>FILES-DELETED.txt</code> or similar, containing the ransom message and payment instructions.</li> </ol>","tags":["aws","security","ransomware"]},{"location":"blog/2025/06/25/defending-s3---anatomy-and-countermeasures-for-encryption-and-deletion-attacks-codefinger-ransomware/#tactic-2-parasitic-encryption-with-sse-c","title":"Tactic 2: Parasitic Encryption with SSE-C","text":"<p>This technique is more subtle and insidious. The data isn't deleted; it's hijacked right under your nose, without a single byte ever leaving your AWS account.</p> <ol> <li>Access: Again, the attacker has credentials with read and write permissions (<code>s3:GetObject</code>, <code>s3:PutObject</code>).</li> <li>The Hijack: The attacker reads an object, but instead of downloading it, they re-write it in place using <code>PutObject</code>, adding a key HTTP header: <code>x-amz-server-side-encryption-customer-key</code>. The value for this header is an AES-256 encryption key that the attacker generates and keeps.</li> <li>The Trick: AWS receives the request, sees the SSE-C (Server-Side Encryption with Customer-Provided Keys) header, and dutifully encrypts the object with the attacker's key. AWS never sees or stores this key. All it records in CloudTrail is an HMAC of the key, which can verify future requests but cannot be used to reconstruct it. The original object is overwritten by an encrypted version that only the attacker can access.</li> <li>The Pressure: To finish the job, actors like the \"Codefinger\" group add a lifecycle policy that marks these encrypted objects for deletion in 7 days. The clock starts ticking.</li> </ol> <p>This attack is especially sneaky because many threat detection systems are configured to look for data exfiltration. There is none here; everything happens inside your perimeter.</p>","tags":["aws","security","ransomware"]},{"location":"blog/2025/06/25/defending-s3---anatomy-and-countermeasures-for-encryption-and-deletion-attacks-codefinger-ransomware/#the-defense-playbook-containment-strategies","title":"The Defense Playbook: Containment Strategies","text":"<p>Protecting yourself requires a defense-in-depth approach. There's no single silver bullet, but rather a set of barriers that makes a successful attack exponentially more difficult.</p>","tags":["aws","security","ransomware"]},{"location":"blog/2025/06/25/defending-s3---anatomy-and-countermeasures-for-encryption-and-deletion-attacks-codefinger-ransomware/#1-immutability-your-primary-line-of-defense","title":"1. Immutability: Your Primary Line of Defense","text":"<p>If an attacker can't delete or overwrite your data, their attack fails. This is non-negotiable.</p> <ul> <li>Enable S3 Versioning: This is the prerequisite for everything else. It lets you preserve, retrieve, and restore every version of every object.</li> <li>Implement S3 Object Lock in Compliance Mode: Versioning alone isn't enough if the attacker has permissions to delete versions. Object Lock in <code>Compliance</code> mode creates a WORM (Write-Once-Read-Many) safeguard. No one, not even the root user, can delete or modify a protected object version before its retention period expires. Set this on your critical buckets. <code>Governance</code> mode is useful for testing, but it can be disabled by privileged users.</li> <li>Require MFA Delete: This is the final protective layer for versioning. It requires any attempt to delete an object version or change the bucket's versioning state to be authenticated with an MFA device. Without it, an attacker with the right credentials could simply disable versioning or delete the versions one by one.</li> </ul>","tags":["aws","security","ransomware"]},{"location":"blog/2025/06/25/defending-s3---anatomy-and-countermeasures-for-encryption-and-deletion-attacks-codefinger-ransomware/#2-abandon-long-lived-credentials","title":"2. Abandon Long-Lived Credentials","text":"<p>The root cause of these attacks is almost always a compromised static access key. Stop using them.</p> <ul> <li>Use IAM Roles: For any workload inside AWS (EC2, Lambda, etc.), use IAM Roles. They provide temporary credentials automatically, eliminating the risk of leaked static keys.</li> <li>IAM Identity Center (SSO): For human access, centralize it with IAM Identity Center. It allows your developers and admins to fetch short-lived credentials for the CLI/SDK, protected by your identity provider and MFA.</li> <li>IAM Roles Anywhere: If you have on-premises systems that need AWS access, this is the way. It lets your own servers obtain temporary AWS credentials using their existing identities (like X.509 certificates) without storing an IAM key on them.</li> </ul>","tags":["aws","security","ransomware"]},{"location":"blog/2025/06/25/defending-s3---anatomy-and-countermeasures-for-encryption-and-deletion-attacks-codefinger-ransomware/#3-block-unnecessary-attack-vectors","title":"3. Block Unnecessary Attack Vectors","text":"<p>If you don't use a feature, disable it.</p> <ul> <li>Block SSE-C with Policies: If your organization has no legitimate use case for Server-Side Encryption with Customer-Provided Keys (and most don't), forbid it. You can do this with a bucket policy or, more forcefully, with a Service Control Policy (SCP) in AWS Organizations that denies any API call containing the <code>x-amz-server-side-encryption-customer-algorithm</code> parameter.</li> </ul> S3 Bucket Policy to Deny SSE-C<pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"DenySSEC\",\n      \"Effect\": \"Deny\",\n      \"Action\": \"s3:PutObject\",\n      \"Resource\": \"arn:aws:s3:::*/*\",\n      \"Condition\": {\n        \"Null\": {\n          \"s3:x-amz-server-side-encryption-customer-algorithm\": \"false\"\n        }\n      }\n    }\n  ]\n}\n</code></pre>","tags":["aws","security","ransomware"]},{"location":"blog/2025/06/24/s3-ransomware-batch-deletion-attack/","title":"S3 Ransomware Batch Deletion Attack","text":"","tags":["aws","security","ransomware"]},{"location":"blog/2025/06/24/s3-ransomware-batch-deletion-attack/#introduction","title":"Introduction","text":"<p>As an AWS security consultant, I've observed the devastating effects of ransomware on AWS S3 buckets. A particularly effective technique employed by attackers involves leveraging the S3 <code>DeleteObjects</code> API for batch deletion. In this post, I'll share my insights on how this attack unfolds and, more importantly, what measures you can implement to safeguard your data.</p>","tags":["aws","security","ransomware"]},{"location":"blog/2025/06/24/s3-ransomware-batch-deletion-attack/#the-attack","title":"The Attack","text":"<p>The S3 ransomware attack targets an S3 bucket by emptying it through batch deletion and then uploading a ransom note. This attack leverages the <code>DeleteObjects</code> API to remove multiple objects and their versions at once, making it a highly efficient way to cause significant data loss.</p>","tags":["aws","security","ransomware"]},{"location":"blog/2025/06/24/s3-ransomware-batch-deletion-attack/#detailed-steps","title":"Detailed Steps","text":"<ol> <li>Listing Objects: The attack starts by listing all objects and their versions in the target S3 bucket using the <code>ListObjectVersions</code> API.</li> <li>Batch Deletion: It then deletes all these objects in a single request using the S3 <code>DeleteObjects</code> API. This API can delete up to 1000 objects at a time.</li> <li> <p>Ransom Note: Finally, the attack uploads a ransom note to the bucket, typically named <code>FILES-DELETED.txt</code>, informing the victim that their data has been \"backed up\" and providing contact information for negotiating its recovery. The content of the ransom note might look like this:</p> <pre><code>Your data is backed up in a safe location. To negotiate with us for recovery, get in touch with rick@astley.io. In 7 days, if we don't hear from you, that data will either be sold or published, and might no longer be recoverable.'\n</code></pre> </li> </ol>","tags":["aws","security","ransomware"]},{"location":"blog/2025/06/24/s3-ransomware-batch-deletion-attack/#mitigation-strategies","title":"Mitigation Strategies","text":"<p>To protect against this type of ransomware attack, consider the following mitigation strategies:</p> <ul> <li>Monitoring and Alerting: Set up monitoring and alerting to detect unusual deletion patterns.</li> <li>Versioning: Enable S3 versioning to keep a history of all object versions. While versioning allows you to recover from accidental or malicious deletions, it doesn't prevent the <code>DeleteObjects</code> API from removing all versions if the attacker has sufficient permissions.</li> <li>MFA Delete: Require multi-factor authentication (MFA) for deleting object versions. This is a critical control, as it requires an additional layer of authentication to permanently delete objects, even with versioning enabled. Without MFA Delete, an attacker with sufficient permissions can bypass versioning by simply deleting all object versions.</li> <li>Bucket Policies: Implement strict bucket policies to control access and restrict deletion permissions.</li> <li>Source: This blog post was inspired by the following resource: Stratus Red Team - S3 Ransomware Batch Deletion</li> </ul>","tags":["aws","security","ransomware"]},{"location":"blog/archive/2025/","title":"2025","text":""}]}